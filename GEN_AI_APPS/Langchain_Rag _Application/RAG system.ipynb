{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6438a3c6-6b6a-44c4-9244-46fc3271ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7699b13b-9c9b-455a-b562-3973750c3ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f3bb81-f70d-4227-9e80-60e979d11433",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(r\"C:\\Users\\HP\\Downloads\\Leave_no_context_paper.pdf\")\n",
    "pages=loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3399d2da-ee9a-4e42-8ad2-09b0da6e01ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 568, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 633, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import NLTKTextSplitter\n",
    "\n",
    "text_splitter = NLTKTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "\n",
    "chunks=text_splitter.split_documents(pages)\n",
    "\n",
    "print(len(chunks))\n",
    "\n",
    "print(type(chunks[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1aafcf1-14b6-4ac5-bfed-6542134995dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Preprint.\\n\\nUnder review.\\n\\nLeave No Context Behind:\\nEfficient Infinite Context Transformers with Infini-attention\\nTsendsuren Munkhdalai, Manaal Faruqui and Siddharth Gopal\\nGoogle\\ntsendsuren@google.com\\nAbstract\\nThis work introduces an efficient method to scale Transformer-based Large\\nLanguage Models (LLMs) to infinitely long inputs with bounded memory\\nand computation.\\n\\nA key component in our proposed approach is a new at-\\ntention technique dubbed Infini-attention.', metadata={'source': 'C:\\\\Users\\\\HP\\\\Downloads\\\\Leave_no_context_paper.pdf', 'page': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac7d261-184c-4954-9084-0ae070f1fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-1.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting google-generativeai<0.6.0,>=0.5.0 (from langchain-google-genai)\n",
      "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.1.45)\n",
      "Collecting google-ai-generativelanguage==0.6.2 (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_api_python_client-2.126.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.20.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.10.12)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.9.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (0.1.49)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.27->langchain-google-genai) (8.2.2)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.27->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1.27->langchain-google-genai) (3.10.1)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (1.62.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai) (2024.2.2)\n",
      "Collecting protobuf (from google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.2->google-generativeai<0.6.0,>=0.5.0->langchain-google-genai)\n",
      "  Downloading grpcio-1.62.2-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Downloading langchain_google_genai-1.0.2-py3-none-any.whl (28 kB)\n",
      "Downloading google_generativeai-0.5.2-py3-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 0.0/146.8 kB ? eta -:--:--\n",
      "   ---------------------------------------  143.4/146.8 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 146.8/146.8 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl (664 kB)\n",
      "   ---------------------------------------- 0.0/664.5 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 92.2/664.5 kB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 368.6/664.5 kB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 553.0/664.5 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  655.4/664.5 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 664.5/664.5 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.3/138.3 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 189.2/189.2 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.126.0-py2.py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.6 MB 9.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/12.6 MB 7.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.2/12.6 MB 7.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 8.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/12.6 MB 8.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.3/12.6 MB 7.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.6/12.6 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.2/12.6 MB 8.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.5/12.6 MB 8.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.8/12.6 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.6 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.6 MB 7.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.8/12.6 MB 7.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.6 MB 7.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.3/12.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.6/12.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.0/12.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.0/12.6 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.0/12.6 MB 7.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.6 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.2/12.6 MB 7.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.6 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.7/12.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.0/12.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.2/12.6 MB 6.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.0/12.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.6/12.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.8/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 6.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.7/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.7/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.7/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 229.1/229.1 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.8/48.8 kB ? eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading grpcio-1.62.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.8 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.1/3.8 MB 10.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.0/3.8 MB 9.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.5/3.8 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.0/3.8 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 7.8 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, rsa, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.62.1\n",
      "    Uninstalling grpcio-1.62.1:\n",
      "      Successfully uninstalled grpcio-1.62.1\n",
      "Successfully installed google-ai-generativelanguage-0.6.2 google-api-core-2.18.0 google-api-python-client-2.126.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.2 googleapis-common-protos-1.63.0 grpcio-1.62.2 grpcio-status-1.62.2 httplib2-0.22.0 langchain-google-genai-1.0.2 proto-plus-1.23.0 protobuf-4.25.3 rsa-4.9 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e3928e-eae6-487f-ac4f-4621c5fb3ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Chunks Embedding\n",
    "# We are just loading OpenAIEmbeddings\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(google_api_key=\"AIzaSyC2Bztff9XtDCDrCJfMJ8py9JaT8VkwSlY\", \n",
    "                                               model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be2b38a-7ec9-4a04-a6d9-df1021309d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the chunks in vector store\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Embed each chunk and load it into the vector store\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./chroma_db_\")\n",
    "\n",
    "# Persist the database on drive\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e74dcde0-48ad-4f72-a70b-74972e5f8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a Connection with the ChromaDB\n",
    "db_connection = Chroma(persist_directory=\"./chroma_db_\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8db8e9c6-3644-49d1-b1fc-99f8783f7a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.vectorstores.VectorStoreRetriever'>\n"
     ]
    }
   ],
   "source": [
    "# Converting CHROMA db_connection to Retriever Object\n",
    "retriever = db_connection.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "print(type(retriever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065ae3cc-81cb-48aa-aa6b-b40e98eae074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb16b1fe-3a79-47c8-b963-4ca87dc6e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    # System Message Prompt Template\n",
    "    SystemMessage(content=\"\"\"You are a Helpful AI Bot. \n",
    "    Your task is to provide assistance based on the context given by the user. \n",
    "    Make sure your answers are relevant and helpful.\"\"\"),\n",
    "    # Human Message Prompt Template\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"Answer the question based on the given context.\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer: \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1533e8a9-1bd8-4f21-8d08-33a9e608d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_model = ChatGoogleGenerativeAI(google_api_key=\"AIzaSyC2Bztff9XtDCDrCJfMJ8py9JaT8VkwSlY\", \n",
    "                                   model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efe655d8-5e09-4dfb-8138-40906b3a2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd6c3e86-a0c3-4e11-b69f-00da5e9b2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | chat_template\n",
    "    | chat_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e720531-c838-482a-9159-4dabfbb53ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Gating Score Visualization Explained\\n\\nBased on the context you provided, gating score visualization refers to the graphical representation of the gating score (sigmoid(β)) for the compressive memory within the Infini-attention model. This visualization helps analyze the behavior of different attention heads within each layer of the model.\\n\\n**Key Points:**\\n\\n* **Figure 3** in the context likely showcases this visualization, plotting the gating scores for all attention heads across different layers.\\n* **Two Types of Heads Emerge:** The visualization reveals two distinct types of attention heads:\\n    * **Specialized Heads:** These have gating scores near 0 or 1, indicating a strong preference for either attending to the compressive memory or the input sequence.\\n    * **Mixer Heads:** These have gating scores close to 0.5, suggesting a balanced approach between the compressive memory and the input sequence.\\n\\n**Purpose of Gating Score Visualization:**\\n\\n* **Understanding Attention Head Behavior:**  It helps researchers analyze how different attention heads utilize the compressive memory and contribute to the model's overall performance.\\n* **Evaluating Compressive Memory Techniques:** By visualizing the gating scores, researchers can assess the effectiveness of different compressive memory techniques and their impact on the model's ability to handle long sequences.\\n\\n**In simpler terms, gating score visualization provides a visual way to understand how the Infini-attention model with its compressive memory focuses on different parts of the input sequence and its memory, ultimately contributing to its ability to process and understand information.** \\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"what is gating score visualization\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01e43046-b656-40f7-a52c-15c453cea7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Gating Score Visualization Explained\n",
       "\n",
       "Based on the context you provided, gating score visualization refers to the graphical representation of the gating score (sigmoid(β)) for the compressive memory within the Infini-attention model. This visualization helps analyze the behavior of different attention heads within each layer of the model.\n",
       "\n",
       "**Key Points:**\n",
       "\n",
       "* **Figure 3** in the context likely showcases this visualization, plotting the gating scores for all attention heads across different layers.\n",
       "* **Two Types of Heads Emerge:** The visualization reveals two distinct types of attention heads:\n",
       "    * **Specialized Heads:** These have gating scores near 0 or 1, indicating a strong preference for either attending to the compressive memory or the input sequence.\n",
       "    * **Mixer Heads:** These have gating scores close to 0.5, suggesting a balanced approach between the compressive memory and the input sequence.\n",
       "\n",
       "**Purpose of Gating Score Visualization:**\n",
       "\n",
       "* **Understanding Attention Head Behavior:**  It helps researchers analyze how different attention heads utilize the compressive memory and contribute to the model's overall performance.\n",
       "* **Evaluating Compressive Memory Techniques:** By visualizing the gating scores, researchers can assess the effectiveness of different compressive memory techniques and their impact on the model's ability to handle long sequences.\n",
       "\n",
       "**In simpler terms, gating score visualization provides a visual way to understand how the Infini-attention model with its compressive memory focuses on different parts of the input sequence and its memory, ultimately contributing to its ability to process and understand information.** \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "\n",
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ffc55fd-f1cc-4151-94cc-0a416925aaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Memory Retrieval and Update in the Context of Compressive Memory\\n\\nBased on the context you provided, it seems we're discussing a specific type of memory management called **compressive memory** used in the context of attention mechanisms for sequence processing. Let's break down memory retrieval and update in this context:\\n\\n**Memory Retrieval:**\\n\\n* **Standard Attention vs. Compressive Memory:** In standard attention mechanisms, key-value (KV) pairs are used to compute attention scores and retrieve relevant information. However, these KV pairs are typically discarded after use. Compressive memory, on the other hand, **stores these old KV states** instead of discarding them.\\n* **Retrieval Process:** When processing new sequences, the system uses the **attention query states** to retrieve relevant values from the stored KV pairs in the compressive memory. This allows the model to access and leverage information from past sequences, effectively creating a long-term memory.\\n\\n**Memory Update:**\\n\\n* **Fixed Size & Information Addition:** Unlike typical memory systems that grow with more data, compressive memory maintains a **fixed number of parameters**. New information is incorporated by **updating these parameters** with the objective of being able to recover the information later during retrieval.\\n* **Objective and Efficiency:** The update process aims to efficiently store information while ensuring it can be accurately retrieved when needed. This involves optimizing the memory's parameters to capture the essence of the new information without exceeding the fixed storage capacity.\\n\\n**Benefits of Compressive Memory:**\\n\\n* **Bounded Storage and Computation:** By maintaining a fixed size, compressive memory avoids the ever-growing memory requirements of standard attention, making it more efficient and scalable for processing long sequences.\\n* **Long-Term Memory Consolidation:** The ability to store and retrieve information from past sequences allows the model to learn and retain long-term dependencies, leading to improved performance on tasks requiring context understanding.\\n\\n**Additional Techniques:**\\n\\nThe provided context also mentions:\\n\\n* **Linear Attention Mechanism:** Compressive memory update and retrieval can be formulated as a linear attention mechanism, allowing for the application of stable training techniques from related methods.\\n* **System-Level Optimization:** Techniques like those proposed by Dao et al. (2022) and Liu et al. (2023) leverage specific hardware architectures to further improve the efficiency of attention computations within compressive memory systems. \\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke(\"Can you please tell me about meory retival and memory update\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7ff1540-566a-4d2e-b581-9b4f4ed39d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Memory Retrieval and Update in the Context of Compressive Memory\n",
       "\n",
       "Based on the context you provided, it seems we're discussing a specific type of memory management called **compressive memory** used in the context of attention mechanisms for sequence processing. Let's break down memory retrieval and update in this context:\n",
       "\n",
       "**Memory Retrieval:**\n",
       "\n",
       "* **Standard Attention vs. Compressive Memory:** In standard attention mechanisms, key-value (KV) pairs are used to compute attention scores and retrieve relevant information. However, these KV pairs are typically discarded after use. Compressive memory, on the other hand, **stores these old KV states** instead of discarding them.\n",
       "* **Retrieval Process:** When processing new sequences, the system uses the **attention query states** to retrieve relevant values from the stored KV pairs in the compressive memory. This allows the model to access and leverage information from past sequences, effectively creating a long-term memory.\n",
       "\n",
       "**Memory Update:**\n",
       "\n",
       "* **Fixed Size & Information Addition:** Unlike typical memory systems that grow with more data, compressive memory maintains a **fixed number of parameters**. New information is incorporated by **updating these parameters** with the objective of being able to recover the information later during retrieval.\n",
       "* **Objective and Efficiency:** The update process aims to efficiently store information while ensuring it can be accurately retrieved when needed. This involves optimizing the memory's parameters to capture the essence of the new information without exceeding the fixed storage capacity.\n",
       "\n",
       "**Benefits of Compressive Memory:**\n",
       "\n",
       "* **Bounded Storage and Computation:** By maintaining a fixed size, compressive memory avoids the ever-growing memory requirements of standard attention, making it more efficient and scalable for processing long sequences.\n",
       "* **Long-Term Memory Consolidation:** The ability to store and retrieve information from past sequences allows the model to learn and retain long-term dependencies, leading to improved performance on tasks requiring context understanding.\n",
       "\n",
       "**Additional Techniques:**\n",
       "\n",
       "The provided context also mentions:\n",
       "\n",
       "* **Linear Attention Mechanism:** Compressive memory update and retrieval can be formulated as a linear attention mechanism, allowing for the application of stable training techniques from related methods.\n",
       "* **System-Level Optimization:** Techniques like those proposed by Dao et al. (2022) and Liu et al. (2023) leverage specific hardware architectures to further improve the efficiency of attention computations within compressive memory systems. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4055605-f262-4e24-a460-fa3142e11aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
